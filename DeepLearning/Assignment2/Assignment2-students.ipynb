{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "Arg = namedtuple('Arg', [\"model\", # type of model: CNN or ANN\n",
    "                         \"batch_size\", # size of training batch: 64, 128\n",
    "                         \"test_batch_size\", # size of testing batch: 1000, 2000\n",
    "                         \"epochs\", # how many epochs?\n",
    "                         \"lr\", # learning rate?\n",
    "                         \"gamma\", # if use adagrad, gamma = ?\n",
    "                         \"seed\", # seed for random\n",
    "                         \"log_interval\", \n",
    "                         \"no_cuda\", # use GPU or not: True or False\n",
    "                         \"dry_run\", # run training 1 batch (to check error)? True or False\n",
    "                         \"save_model\", # want to store model?\n",
    "                         \"checkpoint\", # checkpoint path to store\n",
    "                         \"num_class\", # output classes? 10 or 26\n",
    "                         \"restore_ck\"]) # want to restore model from checkpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, hidden_sizes, num_class):\n",
    "        super(ANN, self).__init__()\n",
    "        # Complete the code (in the ...)\n",
    "        if len(hidden_sizes) != 2:\n",
    "            raise(AttributeError)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, hidden_sizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[1], num_class),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.BatchNorm1d(160),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(CNN1, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 50),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(CNN3, self).__init__()\n",
    "        # Complete the code (in the ...)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 160),\n",
    "            nn.BatchNorm1d(160),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(160, 50),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, num_class),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #labels = torch.eye(3)[labels].to(device)\n",
    "        #target = torch.eye(10)[target]\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            #test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "-----------\n",
    "model: torch model (CNN, ANN)\n",
    "checkpoint: a file path to saved checkpoint\n",
    "\"\"\"\n",
    "def load_model(model, checkpoint):\n",
    "    model.load_state_dict(torch.load(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def main(args, train_loader, test_loader=None, use_cuda=False):\n",
    "    # Training settings\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if args.model == \"ANN\":\n",
    "        # fill the size of hidden layers in ...\n",
    "        model = ANN([256, 128], args.num_class).to(device)\n",
    "    elif args.model == \"CNN\":\n",
    "        model = CNN(args.num_class).to(device)\n",
    "    elif args.model == \"CNN1\":\n",
    "        model = CNN1(args.num_class).to(device)\n",
    "    elif args.model == \"CNN2\":\n",
    "        model = CNN1(args.num_class).to(device)\n",
    "    elif args.model == \"CNN3\":\n",
    "        model = CNN3(args.num_class).to(device)\n",
    "    else:\n",
    "        print(f\"wrong model {args.model}\")\n",
    "        raise(AttributeError)\n",
    "\n",
    "    if args.restore_ck:\n",
    "        # if restore_ck is passed, load model from this checkpoint\n",
    "        load_model(model, args.restore_ck)\n",
    "    \n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        st = time.time()\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        if not test_loader is None:\n",
    "            test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "        print(\"Time for running epoch %i, %.2f\\n\" % (epoch,time.time() - st))\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save({'model_state_dict': model.state_dict()}, args.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code to download MNIST dataset. If errors occur, please create a folder named data & extract MNIST.zip to it.\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "def load_mnist_data(batch_size, use_cuda=False, is_train=True):\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    kwargs = {'batch_size': batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        kwargs.update(cuda_kwargs)\n",
    "    data = datasets.MNIST('./data', train=is_train, download=True, transform=transform)\n",
    "    loader = torch.utils.data.DataLoader(data,**kwargs)\n",
    "    return loader"
   ]
  },
  {
   "source": [
    "## Problem 1. ANN implimentation on mnist\n",
    "- Horay! I got 98% Accuracy!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306846\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.888488\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.537910\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.314381\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.294836\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.330926\n",
      "\n",
      "Test set: Average loss: 0.2931, Accuracy: 9066/10000 (90.6600%)\n",
      "\n",
      "Time for running epoch 1, 4.73\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.297095\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.197884\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.205713\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.190881\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.216584\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.305251\n",
      "\n",
      "Test set: Average loss: 0.1485, Accuracy: 9553/10000 (95.5300%)\n",
      "\n",
      "Time for running epoch 2, 4.51\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.179176\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.179090\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.144916\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.132967\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.123789\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.129139\n",
      "\n",
      "Test set: Average loss: 0.1171, Accuracy: 9631/10000 (96.3100%)\n",
      "\n",
      "Time for running epoch 3, 4.65\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.109367\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.098572\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.117011\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.076796\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.124629\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.098388\n",
      "\n",
      "Test set: Average loss: 0.1920, Accuracy: 9373/10000 (93.7300%)\n",
      "\n",
      "Time for running epoch 4, 4.69\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.176665\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.070708\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.080624\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.073252\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.074840\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.064160\n",
      "\n",
      "Test set: Average loss: 0.0895, Accuracy: 9712/10000 (97.1200%)\n",
      "\n",
      "Time for running epoch 5, 4.71\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.068380\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.076670\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.056613\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.057635\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.089620\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.061727\n",
      "\n",
      "Test set: Average loss: 0.0785, Accuracy: 9756/10000 (97.5600%)\n",
      "\n",
      "Time for running epoch 6, 4.80\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.048463\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.059252\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.036120\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.059957\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.089189\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.053973\n",
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 9749/10000 (97.4900%)\n",
      "\n",
      "Time for running epoch 7, 4.48\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.049683\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.023827\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.038574\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.049792\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.035570\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.035503\n",
      "\n",
      "Test set: Average loss: 0.0725, Accuracy: 9785/10000 (97.8500%)\n",
      "\n",
      "Time for running epoch 8, 4.56\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.031150\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.046534\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.028354\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.050289\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.045516\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.040880\n",
      "\n",
      "Test set: Average loss: 0.0684, Accuracy: 9791/10000 (97.9100%)\n",
      "\n",
      "Time for running epoch 9, 4.50\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.046064\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.027440\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.050815\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.031979\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.021166\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.035397\n",
      "\n",
      "Test set: Average loss: 0.0640, Accuracy: 9808/10000 (98.0800%)\n",
      "\n",
      "Time for running epoch 10, 4.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"ANN\",\n",
    "           batch_size = 1000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 10,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           checkpoint = \"./mnist_ann.pt\",\n",
    "           num_class = 10,\n",
    "           restore_ck=\"\")\n",
    "# use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "train_loader = load_mnist_data(args.batch_size, use_cuda, True)\n",
    "test_loader = load_mnist_data(args.test_batch_size, use_cuda, False)\n",
    "main(args, train_loader, test_loader, use_cuda)"
   ]
  },
  {
   "source": [
    "## Problem 2. CNN implementation on minst\n",
    "- Horay! I got about 99% accuracy!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.448444\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.328828\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.826283\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.632001\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.481766\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.401944\n",
      "\n",
      "Test set: Average loss: 0.1326, Accuracy: 9686/10000 (96.8600%)\n",
      "\n",
      "Time for running epoch 1, 4.41\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.345797\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.310539\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.274107\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.266564\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.277547\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.232469\n",
      "\n",
      "Test set: Average loss: 0.0651, Accuracy: 9814/10000 (98.1400%)\n",
      "\n",
      "Time for running epoch 2, 4.66\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.210858\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.212789\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.223557\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.176408\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.213440\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.205835\n",
      "\n",
      "Test set: Average loss: 0.0510, Accuracy: 9837/10000 (98.3700%)\n",
      "\n",
      "Time for running epoch 3, 4.64\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.142704\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.168778\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.180723\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.187683\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.190996\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.168030\n",
      "\n",
      "Test set: Average loss: 0.0483, Accuracy: 9856/10000 (98.5600%)\n",
      "\n",
      "Time for running epoch 4, 4.59\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.159445\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.125487\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.178130\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.163291\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.140182\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.122604\n",
      "\n",
      "Test set: Average loss: 0.0448, Accuracy: 9865/10000 (98.6500%)\n",
      "\n",
      "Time for running epoch 5, 4.73\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.142541\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.125252\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.135192\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.143375\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.157584\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.136765\n",
      "\n",
      "Test set: Average loss: 0.0424, Accuracy: 9871/10000 (98.7100%)\n",
      "\n",
      "Time for running epoch 6, 4.47\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.140116\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.122612\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.100752\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.128179\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.130356\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.137114\n",
      "\n",
      "Test set: Average loss: 0.0390, Accuracy: 9882/10000 (98.8200%)\n",
      "\n",
      "Time for running epoch 7, 4.66\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.093540\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.114269\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.141820\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.125152\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.108562\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.131785\n",
      "\n",
      "Test set: Average loss: 0.0381, Accuracy: 9880/10000 (98.8000%)\n",
      "\n",
      "Time for running epoch 8, 4.75\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.100354\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.092805\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.126104\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.097170\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.097379\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.095769\n",
      "\n",
      "Test set: Average loss: 0.0382, Accuracy: 9885/10000 (98.8500%)\n",
      "\n",
      "Time for running epoch 9, 4.66\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.084498\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.079279\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.103919\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.098508\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.118093\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.105197\n",
      "\n",
      "Test set: Average loss: 0.0342, Accuracy: 9892/10000 (98.9200%)\n",
      "\n",
      "Time for running epoch 10, 4.57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"CNN\",\n",
    "           batch_size = 1000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 10,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           checkpoint = \"./mnist_cnn.pt\",\n",
    "           num_class = 10,\n",
    "           restore_ck=\"\")\n",
    "# use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "train_loader = load_mnist_data(args.batch_size, use_cuda, True)\n",
    "test_loader = load_mnist_data(args.test_batch_size, use_cuda, False)\n",
    "main(args, train_loader, test_loader, use_cuda)"
   ]
  },
  {
   "source": [
    "## Problem 3. Different settings\n",
    "- I removed some layers starting from the CNN network used in problem 2\n",
    "- CNN1: removed batchnorm and dropout layer, 98.93 accuracy\n",
    "- CNN2: removed batchnorm layer, 98.88 accuracy\n",
    "- CNN3: removed dropout layer, 99.16% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305345\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.939175\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.880527\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.769024\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.410567\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.254416\n",
      "\n",
      "Test set: Average loss: 0.2365, Accuracy: 9321/10000 (93.2100%)\n",
      "\n",
      "Time for running epoch 1, 4.50\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.249881\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.214848\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.217658\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.145303\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.193362\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.127105\n",
      "\n",
      "Test set: Average loss: 0.0951, Accuracy: 9709/10000 (97.0900%)\n",
      "\n",
      "Time for running epoch 2, 4.52\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.071878\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.092237\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.151721\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.103312\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.109331\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.148153\n",
      "\n",
      "Test set: Average loss: 0.0706, Accuracy: 9777/10000 (97.7700%)\n",
      "\n",
      "Time for running epoch 3, 4.60\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.060041\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.085358\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.061373\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.101064\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.091555\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.067221\n",
      "\n",
      "Test set: Average loss: 0.0931, Accuracy: 9729/10000 (97.2900%)\n",
      "\n",
      "Time for running epoch 4, 4.50\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.090343\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.039979\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.069920\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.059936\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.053433\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.035542\n",
      "\n",
      "Test set: Average loss: 0.0579, Accuracy: 9817/10000 (98.1700%)\n",
      "\n",
      "Time for running epoch 5, 4.67\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.055506\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.061829\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.060319\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.046192\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.057297\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.040656\n",
      "\n",
      "Test set: Average loss: 0.0440, Accuracy: 9847/10000 (98.4700%)\n",
      "\n",
      "Time for running epoch 6, 4.58\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.038135\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.038871\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.033297\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.032694\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.031003\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.041769\n",
      "\n",
      "Test set: Average loss: 0.0366, Accuracy: 9878/10000 (98.7800%)\n",
      "\n",
      "Time for running epoch 7, 4.70\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.022596\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.024306\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.047003\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.027980\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.023041\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.041162\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9888/10000 (98.8800%)\n",
      "\n",
      "Time for running epoch 8, 4.68\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.026551\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.027102\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.015782\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.010100\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.015255\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.035776\n",
      "\n",
      "Test set: Average loss: 0.0306, Accuracy: 9901/10000 (99.0100%)\n",
      "\n",
      "Time for running epoch 9, 4.46\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.011061\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.017959\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.011479\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.017265\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.027614\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.029808\n",
      "\n",
      "Test set: Average loss: 0.0337, Accuracy: 9893/10000 (98.9300%)\n",
      "\n",
      "Time for running epoch 10, 4.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"CNN1\",\n",
    "           batch_size = 1000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 10,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           checkpoint = \"./mnist_cnn1.pt\",\n",
    "           num_class = 10,\n",
    "           restore_ck=\"\")\n",
    "# use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "train_loader = load_mnist_data(args.batch_size, use_cuda, True)\n",
    "test_loader = load_mnist_data(args.test_batch_size, use_cuda, False)\n",
    "main(args, train_loader, test_loader, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305345\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.950418\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.922732\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.474127\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.449390\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.255070\n",
      "\n",
      "Test set: Average loss: 0.2274, Accuracy: 9310/10000 (93.1000%)\n",
      "\n",
      "Time for running epoch 1, 4.70\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.239078\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.224721\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.153609\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.449255\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.119101\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.215516\n",
      "\n",
      "Test set: Average loss: 0.0977, Accuracy: 9681/10000 (96.8100%)\n",
      "\n",
      "Time for running epoch 2, 4.66\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.075872\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.103219\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.151234\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.104841\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.143317\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.077033\n",
      "\n",
      "Test set: Average loss: 0.0687, Accuracy: 9777/10000 (97.7700%)\n",
      "\n",
      "Time for running epoch 3, 4.62\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.059327\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.075627\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.079247\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.086912\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.103089\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.063436\n",
      "\n",
      "Test set: Average loss: 0.0613, Accuracy: 9820/10000 (98.2000%)\n",
      "\n",
      "Time for running epoch 4, 4.54\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.055555\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.043250\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.089219\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.057682\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.052306\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.034741\n",
      "\n",
      "Test set: Average loss: 0.0695, Accuracy: 9762/10000 (97.6200%)\n",
      "\n",
      "Time for running epoch 5, 4.58\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.060150\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.071003\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.060354\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.034578\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.065629\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.051084\n",
      "\n",
      "Test set: Average loss: 0.0426, Accuracy: 9867/10000 (98.6700%)\n",
      "\n",
      "Time for running epoch 6, 4.60\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.039565\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.036251\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.031335\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.031739\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.029251\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.041125\n",
      "\n",
      "Test set: Average loss: 0.0356, Accuracy: 9874/10000 (98.7400%)\n",
      "\n",
      "Time for running epoch 7, 4.63\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.023170\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.024140\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.044062\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.028812\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.029355\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.046837\n",
      "\n",
      "Test set: Average loss: 0.0314, Accuracy: 9894/10000 (98.9400%)\n",
      "\n",
      "Time for running epoch 8, 4.56\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.025736\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.031803\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.017143\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.009693\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.019318\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.025177\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9901/10000 (99.0100%)\n",
      "\n",
      "Time for running epoch 9, 4.61\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.013287\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.018565\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.013035\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.018677\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.028106\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.036712\n",
      "\n",
      "Test set: Average loss: 0.0352, Accuracy: 9888/10000 (98.8800%)\n",
      "\n",
      "Time for running epoch 10, 4.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"CNN2\",\n",
    "           batch_size = 1000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 10,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           checkpoint = \"./mnist_cnn2.pt\",\n",
    "           num_class = 10,\n",
    "           restore_ck=\"\")\n",
    "# use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "train_loader = load_mnist_data(args.batch_size, use_cuda, True)\n",
    "test_loader = load_mnist_data(args.test_batch_size, use_cuda, False)\n",
    "main(args, train_loader, test_loader, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.353957\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.607449\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.305973\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.182657\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.123905\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.096999\n",
      "\n",
      "Test set: Average loss: 0.0894, Accuracy: 9850/10000 (98.5000%)\n",
      "\n",
      "Time for running epoch 1, 4.73\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.082156\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.067207\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.052405\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.045633\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.053053\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.041609\n",
      "\n",
      "Test set: Average loss: 0.0445, Accuracy: 9880/10000 (98.8000%)\n",
      "\n",
      "Time for running epoch 2, 4.43\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.024810\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.027479\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.057141\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.049674\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.047721\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.038371\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9899/10000 (98.9900%)\n",
      "\n",
      "Time for running epoch 3, 4.66\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.020955\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.019837\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.016353\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.031800\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.032777\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.022512\n",
      "\n",
      "Test set: Average loss: 0.0315, Accuracy: 9904/10000 (99.0400%)\n",
      "\n",
      "Time for running epoch 4, 4.56\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.016733\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.016358\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.022156\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.014102\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.008690\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.015243\n",
      "\n",
      "Test set: Average loss: 0.0354, Accuracy: 9896/10000 (98.9600%)\n",
      "\n",
      "Time for running epoch 5, 4.71\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.012203\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.007594\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.013012\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.008243\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.014056\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.014187\n",
      "\n",
      "Test set: Average loss: 0.0309, Accuracy: 9903/10000 (99.0300%)\n",
      "\n",
      "Time for running epoch 6, 4.48\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.006954\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.007050\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.006080\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.004725\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.005815\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.009123\n",
      "\n",
      "Test set: Average loss: 0.0303, Accuracy: 9905/10000 (99.0500%)\n",
      "\n",
      "Time for running epoch 7, 4.79\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.006683\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.008619\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.007077\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.006319\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.004317\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.003950\n",
      "\n",
      "Test set: Average loss: 0.0300, Accuracy: 9909/10000 (99.0900%)\n",
      "\n",
      "Time for running epoch 8, 4.62\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.003982\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.009829\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.003051\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.003382\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.002471\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.002964\n",
      "\n",
      "Test set: Average loss: 0.0296, Accuracy: 9906/10000 (99.0600%)\n",
      "\n",
      "Time for running epoch 9, 4.64\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001971\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.001544\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.002173\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.001882\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.001716\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.004073\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 9916/10000 (99.1600%)\n",
      "\n",
      "Time for running epoch 10, 4.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"CNN3\",\n",
    "           batch_size = 1000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 10,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           checkpoint = \"./mnist_cnn3.pt\",\n",
    "           num_class = 10,\n",
    "           restore_ck=\"\")\n",
    "# use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_cuda = True\n",
    "train_loader = load_mnist_data(args.batch_size, use_cuda, True)\n",
    "test_loader = load_mnist_data(args.test_batch_size, use_cuda, False)\n",
    "main(args, train_loader, test_loader, use_cuda)"
   ]
  },
  {
   "source": [
    "## Problem 4. EMnist\n",
    "- This time, I added both dropout and batchnorm layers\n",
    "- Horay! I got 83.98% accuracy!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/156000 (0%)]\tLoss: 3.439113\n",
      "Train Epoch: 1 [30000/156000 (19%)]\tLoss: 2.787060\n",
      "Train Epoch: 1 [60000/156000 (38%)]\tLoss: 2.309239\n",
      "Train Epoch: 1 [90000/156000 (58%)]\tLoss: 1.936414\n",
      "Train Epoch: 1 [120000/156000 (77%)]\tLoss: 1.711180\n",
      "Train Epoch: 1 [150000/156000 (96%)]\tLoss: 1.510648\n",
      "\n",
      "Test set: Average loss: 1.7689, Accuracy: 13059/26000 (50.2269%)\n",
      "\n",
      "Time for running epoch 1, 3.62\n",
      "\n",
      "Train Epoch: 2 [0/156000 (0%)]\tLoss: 1.485983\n",
      "Train Epoch: 2 [30000/156000 (19%)]\tLoss: 1.345832\n",
      "Train Epoch: 2 [60000/156000 (38%)]\tLoss: 1.260921\n",
      "Train Epoch: 2 [90000/156000 (58%)]\tLoss: 1.191450\n",
      "Train Epoch: 2 [120000/156000 (77%)]\tLoss: 1.106349\n",
      "Train Epoch: 2 [150000/156000 (96%)]\tLoss: 1.063372\n",
      "\n",
      "Test set: Average loss: 1.0512, Accuracy: 17988/26000 (69.1846%)\n",
      "\n",
      "Time for running epoch 2, 3.65\n",
      "\n",
      "Train Epoch: 3 [0/156000 (0%)]\tLoss: 1.035487\n",
      "Train Epoch: 3 [30000/156000 (19%)]\tLoss: 0.981803\n",
      "Train Epoch: 3 [60000/156000 (38%)]\tLoss: 0.918141\n",
      "Train Epoch: 3 [90000/156000 (58%)]\tLoss: 0.927802\n",
      "Train Epoch: 3 [120000/156000 (77%)]\tLoss: 0.890727\n",
      "Train Epoch: 3 [150000/156000 (96%)]\tLoss: 0.817731\n",
      "\n",
      "Test set: Average loss: 0.8759, Accuracy: 18945/26000 (72.8654%)\n",
      "\n",
      "Time for running epoch 3, 3.64\n",
      "\n",
      "Train Epoch: 4 [0/156000 (0%)]\tLoss: 0.849751\n",
      "Train Epoch: 4 [30000/156000 (19%)]\tLoss: 0.838121\n",
      "Train Epoch: 4 [60000/156000 (38%)]\tLoss: 0.756086\n",
      "Train Epoch: 4 [90000/156000 (58%)]\tLoss: 0.817055\n",
      "Train Epoch: 4 [120000/156000 (77%)]\tLoss: 0.767114\n",
      "Train Epoch: 4 [150000/156000 (96%)]\tLoss: 0.738646\n",
      "\n",
      "Test set: Average loss: 0.7778, Accuracy: 19667/26000 (75.6423%)\n",
      "\n",
      "Time for running epoch 4, 3.65\n",
      "\n",
      "Train Epoch: 5 [0/156000 (0%)]\tLoss: 0.759043\n",
      "Train Epoch: 5 [30000/156000 (19%)]\tLoss: 0.741096\n",
      "Train Epoch: 5 [60000/156000 (38%)]\tLoss: 0.745302\n",
      "Train Epoch: 5 [90000/156000 (58%)]\tLoss: 0.742765\n",
      "Train Epoch: 5 [120000/156000 (77%)]\tLoss: 0.706290\n",
      "Train Epoch: 5 [150000/156000 (96%)]\tLoss: 0.696439\n",
      "\n",
      "Test set: Average loss: 0.7144, Accuracy: 20071/26000 (77.1962%)\n",
      "\n",
      "Time for running epoch 5, 3.67\n",
      "\n",
      "Train Epoch: 6 [0/156000 (0%)]\tLoss: 0.714221\n",
      "Train Epoch: 6 [30000/156000 (19%)]\tLoss: 0.654744\n",
      "Train Epoch: 6 [60000/156000 (38%)]\tLoss: 0.677044\n",
      "Train Epoch: 6 [90000/156000 (58%)]\tLoss: 0.693252\n",
      "Train Epoch: 6 [120000/156000 (77%)]\tLoss: 0.654087\n",
      "Train Epoch: 6 [150000/156000 (96%)]\tLoss: 0.680445\n",
      "\n",
      "Test set: Average loss: 0.6769, Accuracy: 20475/26000 (78.7500%)\n",
      "\n",
      "Time for running epoch 6, 3.65\n",
      "\n",
      "Train Epoch: 7 [0/156000 (0%)]\tLoss: 0.662145\n",
      "Train Epoch: 7 [30000/156000 (19%)]\tLoss: 0.635537\n",
      "Train Epoch: 7 [60000/156000 (38%)]\tLoss: 0.628821\n",
      "Train Epoch: 7 [90000/156000 (58%)]\tLoss: 0.660112\n",
      "Train Epoch: 7 [120000/156000 (77%)]\tLoss: 0.605103\n",
      "Train Epoch: 7 [150000/156000 (96%)]\tLoss: 0.631761\n",
      "\n",
      "Test set: Average loss: 0.6525, Accuracy: 20643/26000 (79.3962%)\n",
      "\n",
      "Time for running epoch 7, 3.57\n",
      "\n",
      "Train Epoch: 8 [0/156000 (0%)]\tLoss: 0.640743\n",
      "Train Epoch: 8 [30000/156000 (19%)]\tLoss: 0.588346\n",
      "Train Epoch: 8 [60000/156000 (38%)]\tLoss: 0.627039\n",
      "Train Epoch: 8 [90000/156000 (58%)]\tLoss: 0.580545\n",
      "Train Epoch: 8 [120000/156000 (77%)]\tLoss: 0.630975\n",
      "Train Epoch: 8 [150000/156000 (96%)]\tLoss: 0.603853\n",
      "\n",
      "Test set: Average loss: 0.6224, Accuracy: 20882/26000 (80.3154%)\n",
      "\n",
      "Time for running epoch 8, 3.70\n",
      "\n",
      "Train Epoch: 9 [0/156000 (0%)]\tLoss: 0.546381\n",
      "Train Epoch: 9 [30000/156000 (19%)]\tLoss: 0.575458\n",
      "Train Epoch: 9 [60000/156000 (38%)]\tLoss: 0.567058\n",
      "Train Epoch: 9 [90000/156000 (58%)]\tLoss: 0.574388\n",
      "Train Epoch: 9 [120000/156000 (77%)]\tLoss: 0.581357\n",
      "Train Epoch: 9 [150000/156000 (96%)]\tLoss: 0.594383\n",
      "\n",
      "Test set: Average loss: 0.6123, Accuracy: 21019/26000 (80.8423%)\n",
      "\n",
      "Time for running epoch 9, 3.55\n",
      "\n",
      "Train Epoch: 10 [0/156000 (0%)]\tLoss: 0.577981\n",
      "Train Epoch: 10 [30000/156000 (19%)]\tLoss: 0.565363\n",
      "Train Epoch: 10 [60000/156000 (38%)]\tLoss: 0.568518\n",
      "Train Epoch: 10 [90000/156000 (58%)]\tLoss: 0.605250\n",
      "Train Epoch: 10 [120000/156000 (77%)]\tLoss: 0.550176\n",
      "Train Epoch: 10 [150000/156000 (96%)]\tLoss: 0.543432\n",
      "\n",
      "Test set: Average loss: 0.6085, Accuracy: 21043/26000 (80.9346%)\n",
      "\n",
      "Time for running epoch 10, 3.75\n",
      "\n",
      "Train Epoch: 11 [0/156000 (0%)]\tLoss: 0.528850\n",
      "Train Epoch: 11 [30000/156000 (19%)]\tLoss: 0.578637\n",
      "Train Epoch: 11 [60000/156000 (38%)]\tLoss: 0.532111\n",
      "Train Epoch: 11 [90000/156000 (58%)]\tLoss: 0.551970\n",
      "Train Epoch: 11 [120000/156000 (77%)]\tLoss: 0.511844\n",
      "Train Epoch: 11 [150000/156000 (96%)]\tLoss: 0.510817\n",
      "\n",
      "Test set: Average loss: 0.5777, Accuracy: 21232/26000 (81.6615%)\n",
      "\n",
      "Time for running epoch 11, 3.71\n",
      "\n",
      "Train Epoch: 12 [0/156000 (0%)]\tLoss: 0.538414\n",
      "Train Epoch: 12 [30000/156000 (19%)]\tLoss: 0.575039\n",
      "Train Epoch: 12 [60000/156000 (38%)]\tLoss: 0.509283\n",
      "Train Epoch: 12 [90000/156000 (58%)]\tLoss: 0.564377\n",
      "Train Epoch: 12 [120000/156000 (77%)]\tLoss: 0.523852\n",
      "Train Epoch: 12 [150000/156000 (96%)]\tLoss: 0.509016\n",
      "\n",
      "Test set: Average loss: 0.5786, Accuracy: 21271/26000 (81.8115%)\n",
      "\n",
      "Time for running epoch 12, 3.61\n",
      "\n",
      "Train Epoch: 13 [0/156000 (0%)]\tLoss: 0.535101\n",
      "Train Epoch: 13 [30000/156000 (19%)]\tLoss: 0.519645\n",
      "Train Epoch: 13 [60000/156000 (38%)]\tLoss: 0.536322\n",
      "Train Epoch: 13 [90000/156000 (58%)]\tLoss: 0.583371\n",
      "Train Epoch: 13 [120000/156000 (77%)]\tLoss: 0.510930\n",
      "Train Epoch: 13 [150000/156000 (96%)]\tLoss: 0.519591\n",
      "\n",
      "Test set: Average loss: 0.5693, Accuracy: 21340/26000 (82.0769%)\n",
      "\n",
      "Time for running epoch 13, 3.55\n",
      "\n",
      "Train Epoch: 14 [0/156000 (0%)]\tLoss: 0.522967\n",
      "Train Epoch: 14 [30000/156000 (19%)]\tLoss: 0.528339\n",
      "Train Epoch: 14 [60000/156000 (38%)]\tLoss: 0.506720\n",
      "Train Epoch: 14 [90000/156000 (58%)]\tLoss: 0.505560\n",
      "Train Epoch: 14 [120000/156000 (77%)]\tLoss: 0.550367\n",
      "Train Epoch: 14 [150000/156000 (96%)]\tLoss: 0.521110\n",
      "\n",
      "Test set: Average loss: 0.5523, Accuracy: 21429/26000 (82.4192%)\n",
      "\n",
      "Time for running epoch 14, 3.52\n",
      "\n",
      "Train Epoch: 15 [0/156000 (0%)]\tLoss: 0.485320\n",
      "Train Epoch: 15 [30000/156000 (19%)]\tLoss: 0.510931\n",
      "Train Epoch: 15 [60000/156000 (38%)]\tLoss: 0.523283\n",
      "Train Epoch: 15 [90000/156000 (58%)]\tLoss: 0.517271\n",
      "Train Epoch: 15 [120000/156000 (77%)]\tLoss: 0.486855\n",
      "Train Epoch: 15 [150000/156000 (96%)]\tLoss: 0.519143\n",
      "\n",
      "Test set: Average loss: 0.5462, Accuracy: 21511/26000 (82.7346%)\n",
      "\n",
      "Time for running epoch 15, 3.73\n",
      "\n",
      "Train Epoch: 16 [0/156000 (0%)]\tLoss: 0.493572\n",
      "Train Epoch: 16 [30000/156000 (19%)]\tLoss: 0.498818\n",
      "Train Epoch: 16 [60000/156000 (38%)]\tLoss: 0.531515\n",
      "Train Epoch: 16 [90000/156000 (58%)]\tLoss: 0.507818\n",
      "Train Epoch: 16 [120000/156000 (77%)]\tLoss: 0.532676\n",
      "Train Epoch: 16 [150000/156000 (96%)]\tLoss: 0.507550\n",
      "\n",
      "Test set: Average loss: 0.5398, Accuracy: 21569/26000 (82.9577%)\n",
      "\n",
      "Time for running epoch 16, 3.74\n",
      "\n",
      "Train Epoch: 17 [0/156000 (0%)]\tLoss: 0.460303\n",
      "Train Epoch: 17 [30000/156000 (19%)]\tLoss: 0.498144\n",
      "Train Epoch: 17 [60000/156000 (38%)]\tLoss: 0.512691\n",
      "Train Epoch: 17 [90000/156000 (58%)]\tLoss: 0.455598\n",
      "Train Epoch: 17 [120000/156000 (77%)]\tLoss: 0.498223\n",
      "Train Epoch: 17 [150000/156000 (96%)]\tLoss: 0.487298\n",
      "\n",
      "Test set: Average loss: 0.5261, Accuracy: 21635/26000 (83.2115%)\n",
      "\n",
      "Time for running epoch 17, 3.74\n",
      "\n",
      "Train Epoch: 18 [0/156000 (0%)]\tLoss: 0.519361\n",
      "Train Epoch: 18 [30000/156000 (19%)]\tLoss: 0.532740\n",
      "Train Epoch: 18 [60000/156000 (38%)]\tLoss: 0.504708\n",
      "Train Epoch: 18 [90000/156000 (58%)]\tLoss: 0.468050\n",
      "Train Epoch: 18 [120000/156000 (77%)]\tLoss: 0.473034\n",
      "Train Epoch: 18 [150000/156000 (96%)]\tLoss: 0.462716\n",
      "\n",
      "Test set: Average loss: 0.5212, Accuracy: 21688/26000 (83.4154%)\n",
      "\n",
      "Time for running epoch 18, 3.78\n",
      "\n",
      "Train Epoch: 19 [0/156000 (0%)]\tLoss: 0.527715\n",
      "Train Epoch: 19 [30000/156000 (19%)]\tLoss: 0.476232\n",
      "Train Epoch: 19 [60000/156000 (38%)]\tLoss: 0.475838\n",
      "Train Epoch: 19 [90000/156000 (58%)]\tLoss: 0.537735\n",
      "Train Epoch: 19 [120000/156000 (77%)]\tLoss: 0.482657\n",
      "Train Epoch: 19 [150000/156000 (96%)]\tLoss: 0.489871\n",
      "\n",
      "Test set: Average loss: 0.5276, Accuracy: 21663/26000 (83.3192%)\n",
      "\n",
      "Time for running epoch 19, 3.76\n",
      "\n",
      "Train Epoch: 20 [0/156000 (0%)]\tLoss: 0.498330\n",
      "Train Epoch: 20 [30000/156000 (19%)]\tLoss: 0.448430\n",
      "Train Epoch: 20 [60000/156000 (38%)]\tLoss: 0.473283\n",
      "Train Epoch: 20 [90000/156000 (58%)]\tLoss: 0.462490\n",
      "Train Epoch: 20 [120000/156000 (77%)]\tLoss: 0.495088\n",
      "Train Epoch: 20 [150000/156000 (96%)]\tLoss: 0.481058\n",
      "\n",
      "Test set: Average loss: 0.5195, Accuracy: 21718/26000 (83.5308%)\n",
      "\n",
      "Time for running epoch 20, 3.77\n",
      "\n",
      "Train Epoch: 21 [0/156000 (0%)]\tLoss: 0.440276\n",
      "Train Epoch: 21 [30000/156000 (19%)]\tLoss: 0.473332\n",
      "Train Epoch: 21 [60000/156000 (38%)]\tLoss: 0.520468\n",
      "Train Epoch: 21 [90000/156000 (58%)]\tLoss: 0.517013\n",
      "Train Epoch: 21 [120000/156000 (77%)]\tLoss: 0.484657\n",
      "Train Epoch: 21 [150000/156000 (96%)]\tLoss: 0.470010\n",
      "\n",
      "Test set: Average loss: 0.5098, Accuracy: 21771/26000 (83.7346%)\n",
      "\n",
      "Time for running epoch 21, 3.70\n",
      "\n",
      "Train Epoch: 22 [0/156000 (0%)]\tLoss: 0.454316\n",
      "Train Epoch: 22 [30000/156000 (19%)]\tLoss: 0.485857\n",
      "Train Epoch: 22 [60000/156000 (38%)]\tLoss: 0.441817\n",
      "Train Epoch: 22 [90000/156000 (58%)]\tLoss: 0.477514\n",
      "Train Epoch: 22 [120000/156000 (77%)]\tLoss: 0.482199\n",
      "Train Epoch: 22 [150000/156000 (96%)]\tLoss: 0.476828\n",
      "\n",
      "Test set: Average loss: 0.5231, Accuracy: 21692/26000 (83.4308%)\n",
      "\n",
      "Time for running epoch 22, 3.67\n",
      "\n",
      "Train Epoch: 23 [0/156000 (0%)]\tLoss: 0.472602\n",
      "Train Epoch: 23 [30000/156000 (19%)]\tLoss: 0.452477\n",
      "Train Epoch: 23 [60000/156000 (38%)]\tLoss: 0.485583\n",
      "Train Epoch: 23 [90000/156000 (58%)]\tLoss: 0.441863\n",
      "Train Epoch: 23 [120000/156000 (77%)]\tLoss: 0.444143\n",
      "Train Epoch: 23 [150000/156000 (96%)]\tLoss: 0.444622\n",
      "\n",
      "Test set: Average loss: 0.5122, Accuracy: 21800/26000 (83.8462%)\n",
      "\n",
      "Time for running epoch 23, 3.66\n",
      "\n",
      "Train Epoch: 24 [0/156000 (0%)]\tLoss: 0.488120\n",
      "Train Epoch: 24 [30000/156000 (19%)]\tLoss: 0.439615\n",
      "Train Epoch: 24 [60000/156000 (38%)]\tLoss: 0.456354\n",
      "Train Epoch: 24 [90000/156000 (58%)]\tLoss: 0.461282\n",
      "Train Epoch: 24 [120000/156000 (77%)]\tLoss: 0.413802\n",
      "Train Epoch: 24 [150000/156000 (96%)]\tLoss: 0.467641\n",
      "\n",
      "Test set: Average loss: 0.5003, Accuracy: 21873/26000 (84.1269%)\n",
      "\n",
      "Time for running epoch 24, 3.68\n",
      "\n",
      "Train Epoch: 25 [0/156000 (0%)]\tLoss: 0.433162\n",
      "Train Epoch: 25 [30000/156000 (19%)]\tLoss: 0.442926\n",
      "Train Epoch: 25 [60000/156000 (38%)]\tLoss: 0.476259\n",
      "Train Epoch: 25 [90000/156000 (58%)]\tLoss: 0.447265\n",
      "Train Epoch: 25 [120000/156000 (77%)]\tLoss: 0.445044\n",
      "Train Epoch: 25 [150000/156000 (96%)]\tLoss: 0.471707\n",
      "\n",
      "Test set: Average loss: 0.5031, Accuracy: 21824/26000 (83.9385%)\n",
      "\n",
      "Time for running epoch 25, 3.69\n",
      "\n",
      "Train Epoch: 26 [0/156000 (0%)]\tLoss: 0.458606\n",
      "Train Epoch: 26 [30000/156000 (19%)]\tLoss: 0.434060\n",
      "Train Epoch: 26 [60000/156000 (38%)]\tLoss: 0.457864\n",
      "Train Epoch: 26 [90000/156000 (58%)]\tLoss: 0.442647\n",
      "Train Epoch: 26 [120000/156000 (77%)]\tLoss: 0.507504\n",
      "Train Epoch: 26 [150000/156000 (96%)]\tLoss: 0.466239\n",
      "\n",
      "Test set: Average loss: 0.5097, Accuracy: 21779/26000 (83.7654%)\n",
      "\n",
      "Time for running epoch 26, 3.67\n",
      "\n",
      "Train Epoch: 27 [0/156000 (0%)]\tLoss: 0.461951\n",
      "Train Epoch: 27 [30000/156000 (19%)]\tLoss: 0.453414\n",
      "Train Epoch: 27 [60000/156000 (38%)]\tLoss: 0.434663\n",
      "Train Epoch: 27 [90000/156000 (58%)]\tLoss: 0.449437\n",
      "Train Epoch: 27 [120000/156000 (77%)]\tLoss: 0.436055\n",
      "Train Epoch: 27 [150000/156000 (96%)]\tLoss: 0.462198\n",
      "\n",
      "Test set: Average loss: 0.5022, Accuracy: 21830/26000 (83.9615%)\n",
      "\n",
      "Time for running epoch 27, 3.75\n",
      "\n",
      "Train Epoch: 28 [0/156000 (0%)]\tLoss: 0.470025\n",
      "Train Epoch: 28 [30000/156000 (19%)]\tLoss: 0.490265\n",
      "Train Epoch: 28 [60000/156000 (38%)]\tLoss: 0.464070\n",
      "Train Epoch: 28 [90000/156000 (58%)]\tLoss: 0.502649\n",
      "Train Epoch: 28 [120000/156000 (77%)]\tLoss: 0.481620\n",
      "Train Epoch: 28 [150000/156000 (96%)]\tLoss: 0.439758\n",
      "\n",
      "Test set: Average loss: 0.4955, Accuracy: 21913/26000 (84.2808%)\n",
      "\n",
      "Time for running epoch 28, 3.65\n",
      "\n",
      "Train Epoch: 29 [0/156000 (0%)]\tLoss: 0.435909\n",
      "Train Epoch: 29 [30000/156000 (19%)]\tLoss: 0.437172\n",
      "Train Epoch: 29 [60000/156000 (38%)]\tLoss: 0.470541\n",
      "Train Epoch: 29 [90000/156000 (58%)]\tLoss: 0.487248\n",
      "Train Epoch: 29 [120000/156000 (77%)]\tLoss: 0.485281\n",
      "Train Epoch: 29 [150000/156000 (96%)]\tLoss: 0.462840\n",
      "\n",
      "Test set: Average loss: 0.5051, Accuracy: 21848/26000 (84.0308%)\n",
      "\n",
      "Time for running epoch 29, 3.76\n",
      "\n",
      "Train Epoch: 30 [0/156000 (0%)]\tLoss: 0.438375\n",
      "Train Epoch: 30 [30000/156000 (19%)]\tLoss: 0.458687\n",
      "Train Epoch: 30 [60000/156000 (38%)]\tLoss: 0.427211\n",
      "Train Epoch: 30 [90000/156000 (58%)]\tLoss: 0.486469\n",
      "Train Epoch: 30 [120000/156000 (77%)]\tLoss: 0.468923\n",
      "Train Epoch: 30 [150000/156000 (96%)]\tLoss: 0.443887\n",
      "\n",
      "Test set: Average loss: 0.5010, Accuracy: 21836/26000 (83.9846%)\n",
      "\n",
      "Time for running epoch 30, 3.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a data folder & unzip emnist dataset to it. Then, you should see two folder under data (emnist_balance, emnist_test)\n",
    "args = Arg(model=\"CNN\",\n",
    "           batch_size = 3000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 30,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           num_class = 26,\n",
    "           checkpoint = \"./emnist.pt\",\n",
    "           restore_ck=\"\")\n",
    "\n",
    "def loader(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "train_data = ImageFolder(root=\"./data/emnist_balance\", transform=transforms.ToTensor(), loader=loader)\n",
    "test_data = ImageFolder(root=\"./data/emnist_test\", transform=transforms.ToTensor(), loader=loader)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=args.test_batch_size, shuffle=True, num_workers=2)\n",
    "main(args, train_loader, test_loader, use_cuda=True)"
   ]
  },
  {
   "source": [
    "## Problem 5. Transfer learning\n",
    "- Mnist -> Eminst using checkpoint from the problem 2\n",
    "- I don't think it's proper to use network that trained using easier problem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN:\n\tMissing key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.2.weight\", \"model.2.bias\", \"model.2.running_mean\", \"model.2.running_var\", \"model.5.weight\", \"model.5.bias\", \"model.7.weight\", \"model.7.bias\", \"model.7.running_mean\", \"model.7.running_var\", \"model.11.weight\", \"model.11.bias\", \"model.12.weight\", \"model.12.bias\", \"model.12.running_mean\", \"model.12.running_var\", \"model.15.weight\", \"model.15.bias\", \"model.16.weight\", \"model.16.bias\", \"model.16.running_mean\", \"model.16.running_var\", \"model.19.weight\", \"model.19.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\". ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4ae5143ae45f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-75aa00f9929f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train_loader, test_loader, use_cuda)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_ck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# if restore_ck is passed, load model from this checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_ck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-af3808f33d43>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, checkpoint)\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tMissing key(s) in state_dict: \"model.0.weight\", \"model.0.bias\", \"model.2.weight\", \"model.2.bias\", \"model.2.running_mean\", \"model.2.running_var\", \"model.5.weight\", \"model.5.bias\", \"model.7.weight\", \"model.7.bias\", \"model.7.running_mean\", \"model.7.running_var\", \"model.11.weight\", \"model.11.bias\", \"model.12.weight\", \"model.12.bias\", \"model.12.running_mean\", \"model.12.running_var\", \"model.15.weight\", \"model.15.bias\", \"model.16.weight\", \"model.16.bias\", \"model.16.running_mean\", \"model.16.running_var\", \"model.19.weight\", \"model.19.bias\". \n\tUnexpected key(s) in state_dict: \"model_state_dict\". "
     ]
    }
   ],
   "source": [
    "args = Arg(model=\"CNN\",\n",
    "           batch_size = 3000,\n",
    "           test_batch_size = 1000,\n",
    "           epochs = 5,\n",
    "           lr = 1.0,\n",
    "           gamma = 0.7,\n",
    "           seed = 1234,\n",
    "           log_interval = 10,\n",
    "           no_cuda = False,\n",
    "           dry_run = False,\n",
    "           save_model = True,\n",
    "           num_class = 26,\n",
    "           checkpoint = \"./emnist_transfer_from_mnist_cnn.pt\",\n",
    "           restore_ck=\"./mnist_cnn.pt\")\n",
    "\n",
    "def loader(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "train_data = ImageFolder(root=\"./data/emnist_balance\", transform=transforms.ToTensor(), loader=loader)\n",
    "test_data = ImageFolder(root=\"./data/emnist_test\", transform=transforms.ToTensor(), loader=loader)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=args.test_batch_size, shuffle=True, num_workers=2)\n",
    "main(args, train_loader, test_loader, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd04bdc6f543d21430f19fdc68f48a348338922fbb620c2c2e274fc8ce374f8d71d",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}