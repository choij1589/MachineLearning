{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Students can follow the skeleton code to implement their decision regression method.\n",
    "They should fill the todo part to make the code run.\n",
    "\"\"\"\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv\n",
    "def load_csv(filename, cols=None, header=None):\n",
    "    data = pd.read_csv(filename, header=header, names=cols)\n",
    "    data = data.iloc[:,1:]\n",
    "    # print(data)\n",
    "    # data cleasing implementation: filling missing data\n",
    "    \n",
    "    # outlier processing implementation\n",
    "    \n",
    "    return data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    return mean_absolute_error(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "# implement a split method that seperate the dataset into the left branch and the right branch\n",
    "def branch_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] > value:\n",
    "            right.append(row)\n",
    "        else:\n",
    "            left.append(row)\n",
    "        # todo code\n",
    "    return left, right\n",
    "\n",
    "# implement the standard deviation method to select the splitting point\n",
    "def std_index(groups, total):\n",
    "    # get total\n",
    "    # use MEDV for learning \n",
    "    left_and_right = np.array(groups[0][-1] + groups[1][-1])\n",
    "    left = np.array(groups[0][-1])\n",
    "    right = np.array(groups[1][-1])\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        return 0.\n",
    "    all_std = np.var(left_and_right)*len(left_and_right)\n",
    "    left_std = np.var(left)*len(left)\n",
    "    right_std = np.var(right)*len(right)\n",
    "    s_total = total_std - (left_std+right_std)\n",
    "    return s_total\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset, c_idx=None):\n",
    "    dt_length = len(dataset)\n",
    "    b_index, b_value, b_score, b_groups = -1, -1., 0., None\n",
    "    # loop over this column index to find split points\n",
    "    if c_idx is None:\n",
    "        c_idx = list(range(len(dataset[0])-1));\n",
    "    for index in c_idx:\n",
    "        for row in dataset:\n",
    "            # get left | right at the current row-index\n",
    "            groups = branch_split(index, row[index], dataset)\n",
    "            std_score = std_index(groups, dt_length)\n",
    "            matching_criteria = False\n",
    "            if std_score > b_score:\n",
    "                matching_criteria = True\n",
    "            if matching_criteria:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], b_score, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value \n",
    "# generate the prediction result if the tree reaches to this leaf\n",
    "def to_terminal(group):\n",
    "    labels = [row[-1] for row in group]\n",
    "    # implement the aggregation method => make prediction\n",
    "    outputs = np.mean(labels)\n",
    "    return outputs\n",
    " \n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth, c_idx=None):\n",
    "    # remove selected index\n",
    "    # I'm not sure it would work\n",
    "    # input index should not be not\n",
    "    if c_idx == None:\n",
    "        Warning(\"조교야 정신차려\")\n",
    "    c_idx.remove(node['index'])\n",
    "\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, c_idx)\n",
    "        split(node['left'], max_depth, min_size, depth+1, c_idx)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, c_idx)\n",
    "        split(node['right'], max_depth, min_size, depth+1, c_idx)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size, c_idx=None):\n",
    "    root = get_split(train, c_idx)\n",
    "    split(root, max_depth, min_size, 1, c_idx)\n",
    "    return root\n",
    " \n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test, max_depth, min_size, c_idx=None):\n",
    "    tree = build_tree(train, max_depth, min_size, c_idx)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest implementation\n",
    "# 1. implement a shuffle method to shuffle train set\n",
    "# 2. implement a feature random seletion method for each tree, by that it can split branches\n",
    "# 3. implement an ensemble method to aggregate the predicted results\n",
    "\n",
    "def random_forest(n_trees, train_set, test_set, max_depth, min_size, n_features=None):\n",
    "    np.random.seed(12)\n",
    "    predictions = []\n",
    "    \n",
    "    for _ in range(n_trees):\n",
    "        features = random.shuffle(list(range(13)))[0:5]\n",
    "        predictions.append(decision_tree(train_set, test_set,, max_depth, min_size, features))\n",
    "    # todo code\n",
    "    # hint: create multiple decision trees\n",
    "    # aggregate their prediction results => final results\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "\"\"\"\n",
    "- CRIM     per capita crime rate by town\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       average number of rooms per dwelling\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per $10,000\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in $1000's\n",
    "\"\"\"\n",
    "cols = [\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\",\"MEDV\"]\n",
    "# select from housing_100x.csv, housing_100x_missing.csv, housing_100x_outlier.csv, housing_100x_outlier_missing.csv\n",
    "# housing_100x.csv: full data without missing & outlier\n",
    "# housing_100x_missing.csv: intentionally add 5% missing attributes\n",
    "# housing_100x_outlier.csv: intentionally add 5% outlier samples\n",
    "# housing_100x_outlier_missing.csv: intentionally add both missing attributes & outliers\n",
    "filename = 'data/housing_100x.csv' \n",
    "dataset = load_csv(filename, cols=cols, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate algorithm\n",
    "# n_folds = 5\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "# scores = evaluate_algorithm(dataset, n_folds, max_depth, min_size)\n",
    "train_length = int(len(dataset)*0.8)\n",
    "train_set = dataset[:train_length,:]\n",
    "test_set = dataset[train_length:,]\n",
    "predicted = decision_tree(train_set, test_set, max_depth, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 10\n",
    "predicted = random_forest(n_trees, train_set, test_set, max_depth, min_size, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_set[:,-1]\n",
    "scores = accuracy_metric(labels, predicted)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4bdc6f543d21430f19fdc68f48a348338922fbb620c2c2e274fc8ce374f8d71d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}