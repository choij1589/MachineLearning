{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_limit=buffer_limit):\n",
    "        self.buffer = deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        states, actions, rewards, next_states, done_masks = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            sample, action, reward, next_sample, done_mask = transition\n",
    "            states.append(sample)\n",
    "            actions.append([action])\n",
    "            rewards.append([reward])\n",
    "            next_states.append(next_sample)\n",
    "            done_masks.append([done_mask])\n",
    "        \n",
    "        return torch.tensor(states, dtype=torch.float), torch.tensor(actions), torch.tensor(rewards), torch.tensor(next_states, dtype=torch.float), torch.tensor(done_masks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.buffer[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        if random.random() < epsilon:\n",
    "            return random.randint(0, 1)\n",
    "        else:\n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, optimizer):\n",
    "    for _ in range(10):\n",
    "        state, action, reward, next_state, done_mask = memory.sample(batch_size)\n",
    "        \n",
    "        q_out = q(state)\n",
    "        q_a = q_out.gather(1, action)\n",
    "        max_next_q = q_target(next_state).max(1)[0].unsqueeze(1)\n",
    "        target = reward + gamma*max_next_q*done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 20] score: 14.0, n_buffer: 278, epsilon: 0.079\n",
      "[Episode 40] score: 12.0, n_buffer: 531, epsilon: 0.078\n",
      "[Episode 60] score: 10.0, n_buffer: 772, epsilon: 0.077\n",
      "[Episode 80] score: 13.0, n_buffer: 1026, epsilon: 0.076\n",
      "[Episode 100] score: 11.0, n_buffer: 1285, epsilon: 0.075\n",
      "[Episode 120] score: 10.0, n_buffer: 1542, epsilon: 0.074\n",
      "[Episode 140] score: 12.0, n_buffer: 1800, epsilon: 0.07300000000000001\n",
      "[Episode 160] score: 14.0, n_buffer: 2054, epsilon: 0.07200000000000001\n",
      "[Episode 180] score: 13.0, n_buffer: 2288, epsilon: 0.07100000000000001\n",
      "[Episode 200] score: 12.0, n_buffer: 2481, epsilon: 0.07\n",
      "[Episode 220] score: 8.0, n_buffer: 2685, epsilon: 0.069\n",
      "[Episode 240] score: 21.0, n_buffer: 2905, epsilon: 0.068\n",
      "[Episode 260] score: 271.0, n_buffer: 5155, epsilon: 0.067\n",
      "[Episode 280] score: 500.0, n_buffer: 11502, epsilon: 0.066\n",
      "[Episode 300] score: 500.0, n_buffer: 18799, epsilon: 0.065\n",
      "[Episode 320] score: 251.0, n_buffer: 23839, epsilon: 0.064\n",
      "[Episode 340] score: 161.0, n_buffer: 29367, epsilon: 0.063\n",
      "[Episode 360] score: 322.0, n_buffer: 34669, epsilon: 0.062\n",
      "[Episode 380] score: 171.0, n_buffer: 40081, epsilon: 0.061\n",
      "[Episode 400] score: 252.0, n_buffer: 43334, epsilon: 0.06\n",
      "[Episode 420] score: 119.0, n_buffer: 47059, epsilon: 0.059\n",
      "[Episode 440] score: 500.0, n_buffer: 50000, epsilon: 0.057999999999999996\n",
      "[Episode 460] score: 500.0, n_buffer: 50000, epsilon: 0.057\n",
      "[Episode 480] score: 500.0, n_buffer: 50000, epsilon: 0.056\n",
      "[Episode 500] score: 199.0, n_buffer: 50000, epsilon: 0.055\n",
      "[Episode 520] score: 166.0, n_buffer: 50000, epsilon: 0.054\n",
      "[Episode 540] score: 193.0, n_buffer: 50000, epsilon: 0.053\n",
      "[Episode 560] score: 231.0, n_buffer: 50000, epsilon: 0.052000000000000005\n",
      "[Episode 580] score: 213.0, n_buffer: 50000, epsilon: 0.051000000000000004\n",
      "[Episode 600] score: 153.0, n_buffer: 50000, epsilon: 0.05\n",
      "[Episode 620] score: 218.0, n_buffer: 50000, epsilon: 0.049\n",
      "[Episode 640] score: 303.0, n_buffer: 50000, epsilon: 0.048\n",
      "[Episode 660] score: 10.0, n_buffer: 50000, epsilon: 0.047\n",
      "[Episode 680] score: 500.0, n_buffer: 50000, epsilon: 0.046\n",
      "[Episode 700] score: 500.0, n_buffer: 50000, epsilon: 0.045\n",
      "[Episode 720] score: 242.0, n_buffer: 50000, epsilon: 0.044\n",
      "[Episode 740] score: 500.0, n_buffer: 50000, epsilon: 0.043\n",
      "[Episode 760] score: 170.0, n_buffer: 50000, epsilon: 0.042\n",
      "[Episode 780] score: 227.0, n_buffer: 50000, epsilon: 0.041\n",
      "[Episode 800] score: 163.0, n_buffer: 50000, epsilon: 0.04\n",
      "[Episode 820] score: 500.0, n_buffer: 50000, epsilon: 0.03900000000000001\n",
      "[Episode 840] score: 413.0, n_buffer: 50000, epsilon: 0.038\n",
      "[Episode 860] score: 500.0, n_buffer: 50000, epsilon: 0.037000000000000005\n",
      "[Episode 880] score: 500.0, n_buffer: 50000, epsilon: 0.036\n",
      "[Episode 900] score: 215.0, n_buffer: 50000, epsilon: 0.035\n",
      "[Episode 920] score: 284.0, n_buffer: 50000, epsilon: 0.034\n",
      "[Episode 940] score: 500.0, n_buffer: 50000, epsilon: 0.033\n",
      "[Episode 960] score: 118.0, n_buffer: 50000, epsilon: 0.032\n",
      "[Episode 980] score: 178.0, n_buffer: 50000, epsilon: 0.031\n",
      "[Episode 1000] score: 418.0, n_buffer: 50000, epsilon: 0.03\n",
      "[Episode 1020] score: 144.0, n_buffer: 50000, epsilon: 0.029000000000000005\n",
      "[Episode 1040] score: 236.0, n_buffer: 50000, epsilon: 0.027999999999999997\n",
      "[Episode 1060] score: 281.0, n_buffer: 50000, epsilon: 0.027000000000000003\n",
      "[Episode 1080] score: 500.0, n_buffer: 50000, epsilon: 0.025999999999999995\n",
      "[Episode 1100] score: 500.0, n_buffer: 50000, epsilon: 0.025\n",
      "[Episode 1120] score: 500.0, n_buffer: 50000, epsilon: 0.024000000000000007\n",
      "[Episode 1140] score: 310.0, n_buffer: 50000, epsilon: 0.023\n",
      "[Episode 1160] score: 159.0, n_buffer: 50000, epsilon: 0.022000000000000006\n",
      "[Episode 1180] score: 500.0, n_buffer: 50000, epsilon: 0.020999999999999998\n",
      "[Episode 1200] score: 500.0, n_buffer: 50000, epsilon: 0.020000000000000004\n",
      "[Episode 1220] score: 237.0, n_buffer: 50000, epsilon: 0.019000000000000003\n",
      "[Episode 1240] score: 500.0, n_buffer: 50000, epsilon: 0.017999999999999995\n",
      "[Episode 1260] score: 108.0, n_buffer: 50000, epsilon: 0.017\n",
      "[Episode 1280] score: 211.0, n_buffer: 50000, epsilon: 0.016\n",
      "[Episode 1300] score: 500.0, n_buffer: 50000, epsilon: 0.015\n",
      "[Episode 1320] score: 382.0, n_buffer: 50000, epsilon: 0.013999999999999999\n",
      "[Episode 1340] score: 187.0, n_buffer: 50000, epsilon: 0.012999999999999998\n",
      "[Episode 1360] score: 19.0, n_buffer: 50000, epsilon: 0.011999999999999997\n",
      "[Episode 1380] score: 122.0, n_buffer: 50000, epsilon: 0.010999999999999996\n",
      "[Episode 1400] score: 390.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1420] score: 170.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1440] score: 102.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1460] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1480] score: 162.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1500] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1520] score: 217.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1540] score: 118.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1560] score: 147.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1580] score: 127.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1600] score: 113.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1620] score: 95.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1640] score: 103.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1660] score: 120.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1680] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1700] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1720] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1740] score: 250.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1760] score: 232.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1780] score: 134.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1800] score: 20.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1820] score: 71.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1840] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1860] score: 436.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1880] score: 98.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1900] score: 188.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1920] score: 228.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1940] score: 500.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1960] score: 130.0, n_buffer: 50000, epsilon: 0.01\n",
      "[Episode 1980] score: 126.0, n_buffer: 50000, epsilon: 0.01\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "q = QNet()\n",
    "q_target = QNet()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "\n",
    "for n_epi in range(2000):\n",
    "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200))\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0.\n",
    "    \n",
    "    while not done:\n",
    "        action = q.sample_action(torch.from_numpy(state).float(), epsilon)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        done_mask = 0. if done else 1.\n",
    "        memory.put((state, action, reward/100., next_state, done_mask))\n",
    "        state = next_state\n",
    "        \n",
    "        score += reward\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    if len(memory) > 2000:\n",
    "        train(q, q_target, memory, optimizer)\n",
    "    \n",
    "    if n_epi % 20 == 0 and n_epi != 0:\n",
    "        q_target.load_state_dict(q.state_dict())\n",
    "        print(f\"[Episode {n_epi}] score: {score}, n_buffer: {len(memory)}, epsilon: {epsilon}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86ccdcb783a3baf0aadc75153d57a6ddbd2dc9e8dd9d72826f65f1dd39ff8e8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
