{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "class GridWorld():\n",
    "    \"\"\"The size of the grid is (4 x 4)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "    \n",
    "    def step(self, action):\n",
    "        # action should be an integer between 0 ~ 3\n",
    "        if type(action) != int:\n",
    "            raise(TypeError)\n",
    "        \n",
    "        if action == 0:\n",
    "            self.move_right()\n",
    "        elif action == 1:\n",
    "            self.move_left()\n",
    "        elif action == 2:\n",
    "            self.move_up()\n",
    "        elif action == 3:\n",
    "            self.move_down()\n",
    "        else:\n",
    "            print(f\"action should be an integer between 0 and 3, received {action}\")\n",
    "            raise(ValueError)\n",
    "            \n",
    "        reward = -1\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "    \n",
    "    def move_right(self):\n",
    "        self.y += 1\n",
    "        if self.y > 3:\n",
    "            self.y = 3\n",
    "\n",
    "    def move_left(self):\n",
    "        self.y -= 1\n",
    "        if self.y < 0:\n",
    "            self.y = 0\n",
    "            \n",
    "    def move_up(self):\n",
    "        self.x -= 1\n",
    "        if self.x < 0:\n",
    "            self.x = 0\n",
    "    \n",
    "    def move_down(self):\n",
    "        self.x += 1\n",
    "        if self.x > 3:\n",
    "            self.x = 3\n",
    "    \n",
    "    def is_done(self):\n",
    "        if self.x == 3 and self.y == 3:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        return (self.x, self.y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class Agent():\n",
    "    def __init__(self, update=\"Monte-Carlo\"):\n",
    "        if update not in [\"Monte-Carlo\", \"Temporal-Difference\"]:\n",
    "            raise(ValueError)\n",
    "        self.update = update\n",
    "        self.v_table = np.zeros((4, 4))\n",
    "        if update == \"Monte-Carlo\":\n",
    "            self.gamma = 1.\n",
    "            self.alpha = 0.0001\n",
    "        elif update == \"Temporal-Difference\":\n",
    "            self.gamma = 1.\n",
    "            self.alpha = 0.01\n",
    "    \n",
    "    def select_action(self):\n",
    "        return random.randint(0, 3)\n",
    "    \n",
    "    def update_table(self, update_info):\n",
    "        if self.update == \"Monte-Carlo\":\n",
    "            history = update_info\n",
    "            cum_reward = 0.\n",
    "            for transition in history[::-1]:\n",
    "                x, y, reward = transition\n",
    "                self.v_table[x, y] += self.alpha*(cum_reward - self.v_table[x, y])\n",
    "                cum_reward += self.gamma*reward\n",
    "                \n",
    "        elif self.update == \"Temporal-Difference\":\n",
    "            transition = update_info\n",
    "            state, action, reward, next_state = transition\n",
    "            x, y = state\n",
    "            next_x, next_y = next_state\n",
    "            self.v_table[x, y] += self.alpha*(reward+self.gamma*self.v_table[next_x, next_y] - self.v_table[x, y])\n",
    "            \n",
    "        else:\n",
    "            raise(ValueError)\n",
    "    \n",
    "    def show_table(self):\n",
    "        for row in self.v_table:\n",
    "            print(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Using Monte Carlo\n",
    "env = GridWorld()\n",
    "agent = Agent(update=\"Monte-Carlo\")\n",
    "\n",
    "for _ in range(50000):\n",
    "    done = False\n",
    "    history = []\n",
    "    while not done:\n",
    "        action = agent.select_action()\n",
    "        (x, y), reward, done = env.step(action)\n",
    "        history.append((x, y, reward))\n",
    "    env.reset()\n",
    "    \n",
    "    agent.update_table(history)\n",
    "\n",
    "agent.show_table()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-60.00127336 -57.84612229 -54.4565365  -52.06730038]\n",
      "[-58.06604955 -55.10799589 -49.65119574 -45.0224462 ]\n",
      "[-54.29151834 -49.73301344 -40.95807082 -29.61830632]\n",
      "[-51.84281682 -45.1505227  -30.08245869   0.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Using Temporal Difference\n",
    "env = GridWorld()\n",
    "agent = Agent(update=\"Temporal-Difference\")\n",
    "\n",
    "for _ in range (50000):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "        action = agent.select_action()\n",
    "        next_state, reward, done = env.step(action)\n",
    "        transition = (state, action, reward, next_state)\n",
    "        agent.update_table(transition)\n",
    "        state = next_state\n",
    "    env.reset()\n",
    "    \n",
    "agent.show_table()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-59.13007012 -57.04200392 -54.13116821 -51.93487473]\n",
      "[-57.2184961  -54.6506139  -49.56895552 -45.50343726]\n",
      "[-53.72962442 -49.17296891 -40.98221112 -31.93714304]\n",
      "[-51.94851658 -45.26491244 -29.44788658   0.        ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "86ccdcb783a3baf0aadc75153d57a6ddbd2dc9e8dd9d72826f65f1dd39ff8e8a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}